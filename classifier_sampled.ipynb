{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib as plt\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(num):\n",
    "    return 0 if num <= 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF: 653\n",
      "Not CF 8794\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('C:\\\\Users\\\\Jerem\\\\Documents\\\\Spring 2023\\\\HourlyWork\\\\CF-dataset.csv', encoding='utf8')\n",
    "print('CF:', df['Label'].tolist().count(1))\n",
    "print('Not CF', df['Label'].tolist().count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1200\n",
    "df_label_0 = df[df['Label'] == 0]  # select only rows with label == 0\n",
    "df_label_0_sample = df_label_0.sample(n=n_samples, random_state=42)  # randomly sample N rows\n",
    "\n",
    "df_label_1 = df[df['Label'] == 1]  # select only rows with label == 1\n",
    "sample_df = pd.concat([df_label_0_sample, df_label_1])\n",
    "\n",
    "# # Use the sample df\n",
    "X = sample_df['Text'].to_list()\n",
    "Y = sample_df['Label'].to_list()\n",
    "\n",
    "moods = sample_df['Moods'].tolist()\n",
    "moods_binarized = [mood.count('Sub') for mood in moods]\n",
    "si_presence = [binarize(text.count('si')) for text in X]\n",
    "\n",
    "\n",
    "sub_count = []\n",
    "for i in range(len(Y)):\n",
    "    if Y[i] == 1:\n",
    "        if 'Sub' in moods[i]:\n",
    "            count = int(moods[i][moods[i].index('Sub'):moods[i].index('Sub')+7][-1])\n",
    "        else:\n",
    "            count = 0\n",
    "\n",
    "    if Y[i] == 0:\n",
    "        if 'Sub' in moods[i]:\n",
    "            count = int(moods[i][moods[i].index('Sub'):moods[i].index('Sub')+7][-1])\n",
    "        else:\n",
    "            count = 0\n",
    "    sub_count.append(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CF: 653\n",
      "All not CF: 1200\n",
      "Training data: 1297\n",
      "Testing data: 556\n",
      "Training distribution: Not-CF: 840 CF 457\n",
      "Testing distribution: Not-CF: 360 CF 196\n",
      "[0.77208333 1.41883614]\n",
      "(1297, 82043) (1297, 4279)\n",
      "(1297, 86324)\n",
      "  (0, 4223)\t0.0645143765149309\n",
      "  (0, 4222)\t0.06320447449831673\n",
      "  (0, 4093)\t0.05008706661039327\n",
      "  (0, 4092)\t0.04642467652660271\n",
      "  (0, 4013)\t0.0617158939822226\n",
      "  (0, 4012)\t0.06092468749080152\n",
      "  (0, 3862)\t0.03195984896846458\n",
      "  (0, 3733)\t0.1686498531896496\n",
      "  (0, 3730)\t0.06646813999282902\n",
      "  (0, 3554)\t0.05277908179998496\n",
      "  (0, 3550)\t0.06533359497350706\n",
      "  (0, 3542)\t0.15399666343947896\n",
      "  (0, 3541)\t0.19990639771464444\n",
      "  (0, 3523)\t0.07665300537954782\n",
      "  (0, 3520)\t0.06580025355607075\n",
      "  (0, 3505)\t0.07953822051679377\n",
      "  (0, 3499)\t0.05559556763870498\n",
      "  (0, 3440)\t0.12435376469803837\n",
      "  (0, 3435)\t0.041369992338215006\n",
      "  (0, 3421)\t0.09119176608819284\n",
      "  (0, 3420)\t0.0710034151538282\n",
      "  (0, 3390)\t0.08085708304303289\n",
      "  (0, 3380)\t0.03406426889243867\n",
      "  (0, 3375)\t0.07329154412979208\n",
      "  (0, 3361)\t0.035328366366858856\n",
      "  :\t:\n",
      "  (555, 176)\t0.08886908944659919\n",
      "  (555, 155)\t0.0602207146628231\n",
      "  (555, 151)\t0.054467777900267196\n",
      "  (555, 146)\t0.04309960901624094\n",
      "  (555, 141)\t0.023324743080168537\n",
      "  (555, 134)\t0.030295546009971513\n",
      "  (555, 130)\t0.07924529991996787\n",
      "  (555, 128)\t0.08661285150291446\n",
      "  (555, 100)\t0.03141818860631568\n",
      "  (555, 99)\t0.026393454713651617\n",
      "  (555, 84)\t0.048861444725007155\n",
      "  (555, 77)\t0.03764107122209962\n",
      "  (555, 73)\t0.08245291010757548\n",
      "  (555, 69)\t0.02776131481324041\n",
      "  (555, 67)\t0.02881318416255058\n",
      "  (555, 60)\t0.10692831931446285\n",
      "  (555, 54)\t0.03599078667245209\n",
      "  (555, 52)\t0.0674907809329674\n",
      "  (555, 50)\t0.08216543549487265\n",
      "  (555, 44)\t0.027438526375854037\n",
      "  (555, 38)\t0.022673832728099995\n",
      "  (555, 22)\t0.07191292524378282\n",
      "  (555, 6)\t0.05540136846447927\n",
      "  (555, 3)\t0.07918036414095485\n",
      "  (555, 2)\t0.10398578528644128 (556, 82043)\n",
      "(556, 86324)\n"
     ]
    }
   ],
   "source": [
    "# Use sub presence\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, mood_train, mood_test, si_train, si_test = train_test_split(X, \n",
    "                                                                                              Y, \n",
    "                                                                                              moods_binarized, \n",
    "                                                                                              si_presence, \n",
    "                                                                                              test_size=0.3, \n",
    "                                                                                              random_state=42, \n",
    "                                                                                              stratify=Y, \n",
    "                                                                                              shuffle=True)\n",
    "print('All CF:',Y.count(1))\n",
    "print('All not CF:', Y.count(0))\n",
    "print('Training data: {}'.format(len(X_train)))\n",
    "print('Testing data: {}'.format(len(X_test)))\n",
    "print('Training distribution:', 'Not-CF:', y_train.count(0), 'CF', y_train.count(1))\n",
    "print('Testing distribution:', 'Not-CF:', y_test.count(0), 'CF', y_test.count(1))\n",
    "\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=[0,1], y=Y)\n",
    "print(class_weights)\n",
    "\n",
    "\n",
    "# create TF-IDF vectorizer with n-grams\n",
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(2, 3), encoding='utf-8')\n",
    "tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 3), encoding='utf-8')\n",
    "\n",
    "# fit and transform the training data\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "char_train = tfidf_char.fit_transform(X_train)\n",
    "\n",
    "print(X_train_tfidf.shape, char_train.shape)\n",
    "X_train_tfidf = sparse.hstack((X_train_tfidf, np.array(mood_train)[:,None], np.array(si_train)[:,None]))\n",
    "X_train_tfidf = sparse.hstack([X_train_tfidf, char_train])\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "\n",
    "# transform the testing data using the same vectorizer\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "char_test = tfidf_char.transform(X_test)\n",
    "print(char_test, X_test_tfidf.shape)\n",
    "\n",
    "X_test_tfidf = sparse.hstack((X_test_tfidf, np.array(mood_test)[:,None], np.array(si_test)[:,None]))\n",
    "X_test_tfidf = sparse.hstack([X_test_tfidf, char_test])\n",
    "print(X_test_tfidf.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Use Sub Count\n",
    "\n",
    "# # split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test, sub_count_train, sub_count_test, si_train, si_test = train_test_split(X, \n",
    "#                                                                                               Y, \n",
    "#                                                                                               sub_count, \n",
    "#                                                                                               si_presence, \n",
    "#                                                                                               test_size=0.2, \n",
    "#                                                                                               random_state=42, \n",
    "#                                                                                               stratify=Y, \n",
    "#                                                                                               shuffle=True)\n",
    "# print('All CF:',Y.count(1))\n",
    "# print('All not CF:', Y.count(0))\n",
    "# print('Training data: {}'.format(len(X_train)))\n",
    "# print('Testing data: {}'.format(len(X_test)))\n",
    "# print('Training distribution:', 'Not-CF:', y_train.count(0), 'CF', y_train.count(1))\n",
    "# print('Testing distribution:', 'Not-CF:', y_test.count(0), 'CF', y_test.count(1))\n",
    "\n",
    "# class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=[0,1], y=Y)\n",
    "# print(class_weights)\n",
    "\n",
    "\n",
    "# # create TF-IDF vectorizer with n-grams\n",
    "# tfidf = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 3), encoding='utf-8')\n",
    "\n",
    "# # fit and transform the training data\n",
    "# X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "# print(X_train_tfidf.shape)\n",
    "\n",
    "# X_train_tfidf = sparse.hstack((X_train_tfidf, np.array(sub_count_train)[:,None], np.array(si_train)[:,None]))\n",
    "# print(X_train_tfidf.shape)\n",
    "\n",
    "\n",
    "# # transform the testing data using the same vectorizer\n",
    "# X_test_tfidf = tfidf.transform(X_test)\n",
    "# print(X_test_tfidf.shape)\n",
    "\n",
    "# X_test_tfidf = sparse.hstack((X_test_tfidf, np.array(sub_count_test)[:,None], np.array(si_test)[:,None]))\n",
    "# print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "{'C': 5, 'decision_function_shape': 'ovo', 'gamma': 'auto', 'kernel': 'linear'} 0.8189960801341476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define SVM classifier\n",
    "svm = SVC(class_weight={0: class_weights[0], 1: class_weights[1]})\n",
    "\n",
    "# define hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 5, 10],\n",
    "    'gamma': ['auto', 'scale'],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'decision_function_shape' : ['ovo']\n",
    "}\n",
    "\n",
    "# perform grid search\n",
    "grid_search = GridSearchCV(svm, param_grid, scoring='f1', verbose=3, n_jobs=3)\n",
    "                           \n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# get best hyperparameters and accuracy\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(best_params, best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.41007194244604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       360\n",
      "           1       0.79      0.87      0.83       196\n",
      "\n",
      "    accuracy                           0.87       556\n",
      "   macro avg       0.86      0.87      0.87       556\n",
      "weighted avg       0.88      0.87      0.88       556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train SVM classifier with best hyperparameters\n",
    "svm = SVC(class_weight={0: class_weights[0], 1: class_weights[1]}, **best_params)\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# predict on the testing data and calculate accuracy\n",
    "y_pred = svm.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy*100)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4c35ab18d64beb73eb5bd0a413aff9d7b8895fdc9746fe77e18c17c088a689f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
